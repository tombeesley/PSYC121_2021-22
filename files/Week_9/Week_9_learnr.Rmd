---
title: 'PSYC121: Week 9 Lab'
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered

---

```{r setup, include=FALSE, exercise.startover = TRUE}
library(tidyverse)
library(learnr)

load("tidy_data.RData")

data_raw <- data
colnames(data)

data <- 
  data_raw %>% 
  select(sibling_order, countries_visited, climate_estimate) %>% 
  mutate(sibling_order = case_when(sibling_order == "The oldest of my siblings" ~ "oldest",
                                   sibling_order == "The youngest of my siblings" ~ "youngest",
                                   sibling_order == "A middle child (I had older and younger siblings)" ~ "middle",
                                   sibling_order == "An only child" ~ "only_child")) %>% 
  drop_na()

data_z <- 
  data %>% 
  mutate(cv_z = scale(countries_visited)) # make z-scores from raw values

knitr::opts_chunk$set(echo = FALSE)
```

## Testing your knowledge

Before we get started on some new stuff, let's try testing your knowledge of what you've learnt over the last few weeks. With each test, try to first do it from memory, then if you have to, use either the hints, or search through the course instructions (or your notes) to find the relevant tuition.

First, let's take a look at the data we have to work with. Use the box below to get a `summary()` to find out information about the columns of data. You might also like to use `head(data)` to see the first few rows, or `count(data, sibling_order)` to see the values on that column.

```{r dotplot, exercise=TRUE}

summary(data)

```

Use the box below to draw a `geom_histogram()` of the *countries_visited* variable. Use the hints if you get stuck.

```{r histogram, exercise=TRUE}

data %>% 
  # add your code here to draw a histogram


```
```{r histogram-hint-1}

data %>% 
  ggplot() +

```
```{r histogram-hint-2}

data %>% 
  ggplot() +
  geom_histogram(aes())

```

What is the `mean()` of the *countries_visited* column?

```{r mean, exercise=TRUE}

# add code here to calculate the mean of the column

```
```{r mean-hint-1}

mean()

```
```{r mean-hint-2}

#mean(data$ )

```

Now let's look at the `mean()` of the countries visited, but split the data up according to whether people were youngest, oldest, middle-child, or only-child. Use a `group_by()` and `summarise()` command to do this:

```{r group_by, exercise=TRUE}

data %>% 
  # add your code here to perform a group_by 
  # add your code here to summarise data in these groups


```
```{r group_by-hint-1}

data %>% 
  group_by() %>% 
  summarise()

```
```{r group_by-hint-2}

data %>% 
  group_by(sibling_order) %>% 
  summarise()

```

Now let's `filter()` the data and draw a new plot. Let's select all of those survey responses where the person rated the impact of human activity on climate change as being 80 or above (out of 100), and then plot the number of countries they visited with a `geom_density()`. 

```{r filter, exercise=TRUE}

data %>% 
  # add your code here to perform a filter
  # add code here to draw a density plot of the data

```
```{r filter-hint-1}

data %>% 
  filter(climate_estimate ) # incomplete

```
```{r filter-hint-2}

data %>% 
  filter(climate_estimate )  %>% # incomplete
  ggplot() +

```
```{r filter-hint-3}

data %>% 
  filter(climate_estimate )  %>% # incomplete
  ggplot() +
  geom_density(aes()) # incomplete

```


## Creating a z-score variable

We have seen in previous weeks that we can create new variables using the `mutate()` function. Let's use that in combination with the `scale()` function to create a new z-score for the *countries_visited* variable:

```{r mutate_z, exercise=TRUE}

data_z <- 
  data %>% 
  mutate(cv_z = scale(countries_visited)) # make z-scores from raw values

head(data_z) # view the top rows

```

Use the box below to calculate the `mean()`, `sd()`, `min()` and `max()` of the *cv_z* column:

```{r stats_z, exercise=TRUE, exercise.setup = "z-setup"}

# mean
# sd
# min
# max

```

If you do this correctly, you'll get a rather strange value for the mean, and a value of 1 for the sd. The mean is actually very close to the value of 0 (note the scientific notation), which is what we would expect. Remember that z-scores reflect a transformation of the data to a distribution with a mean of 0 and a standard deviation of 1. 

Let's look at this distribution with a density plot:

```{r density_z, exercise=TRUE, exercise.setup = "z-setup"}

data_z %>% 
  ggplot() + 
  geom_density(aes(x = cv_z))


```

Does this help you understand why the `max()` is a larger z score than the `min()`? The data are clearly positively skewed. Consider what the data represent - why might the data be positively skewed for this variable?

By converting our variable to z-scores, we now have a way in which we can remove the data that we consider to be "extreme" or "unusual". Importantly, we're not just eye-balling the data now. We know from the previous calcuation that the min value is not that extreme (the negative side of the z-distribution), but there are some extreme values on the positive side of the z-distribution. Let's filter all those above 2.5:

```{r z_filter, exercise=TRUE, exercise.setup = "z-setup"}

data_z_f <- 
  data_z %>% 
  filter() # edit this filter to KEEP the values below 2.5

# let's look at the density plot now.
data_z_f %>% 
  ggplot() + 
  geom_density(aes(x = cv_z))

```

Great work! That ends the exercises today. We've kept it fairly short so that you have plenty of time to go over old material. So if you got stuck on any of the earlier bits, and need to revise that content, please do spend some time on that. Please complete the other prep work so you are ready to start the main tasks in the lab. See you then.

